# AI-Powered-Financial-Transactions-Pipeline

# ğŸ’¸ AI-Powered Financial Transactions Pipeline  
> Scalable backend service with real-time anomaly detection and LLM-driven insights

![FastAPI](https://img.shields.io/badge/FastAPI-0.115.0-009688?logo=fastapi)
![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python)
![Docker](https://img.shields.io/badge/Docker-ready-0db7ed?logo=docker)
![License](https://img.shields.io/badge/license-MIT-green)

---

## ğŸ“˜ Overview
This project is a **production-ready FastAPI service** that ingests, stores, and analyzes financial transactions at scale.  
It combines **statistical anomaly detection** with **AI-powered reasoning (OpenAI + LangChain)** to identify suspicious transactions and provide concise natural-language explanations.

The system is designed to handle **1M+ transactions per day** using asynchronous I/O and modern Python tooling.

---

## ğŸš€ Key Features

âœ… **FastAPI REST API** â€” CRUD and analytics endpoints  
âœ… **Scalable architecture** â€” PostgreSQL + SQLAlchemy 2.0  
âœ… **Anomaly Detection** â€” z-score and rule-based hybrid  
âœ… **LLM Integration (optional)** â€” OpenAI via LangChain for intelligent insights  
âœ… **Dockerized Deployment** â€” ready for local or cloud (Azure / AWS / GCP)  
âœ… **Real-time monitoring** â€” structured logs and API health checks  
âœ… **Unit Tests** â€” pytest + httpx for async endpoint validation  

---

## ğŸ—ï¸ Architecture

```text
+-------------+     +--------------------+     +---------------------+
| Client / UI | ---> | FastAPI Service   | ---> | PostgreSQL Database |
+-------------+       | â€¢ /ingest         |       | â€¢ transactions      |
| â€¢ /anomalies |      +-------------------+       +---------------------+
| â€¢ /insights (LLM) |
+--------------------+
          |
          v
+--------------------+
| OpenAI (LLM)       |
| LangChain Pipeline |
+--------------------+
```
---

## âš™ï¸ Tech Stack

| Layer | Technology |
|-------|-------------|
| API Framework | FastAPI |
| Database | PostgreSQL + SQLAlchemy 2.0 |
| Deployment | Docker & Docker Compose |
| ML/AI Layer | NumPy, OpenAI API, LangChain |
| DevOps | Uvicorn, pytest, dotenv |
| Language | Python 3.11 |

---

## ğŸ“‚ Project Structure

```text
ai-fin-transactions-pipeline/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI entry point
â”‚   â”œâ”€â”€ config.py            # Environment & settings
â”‚   â”œâ”€â”€ database.py          # SQLAlchemy engine & session
â”‚   â”œâ”€â”€ models.py            # ORM models
â”‚   â”œâ”€â”€ schemas.py           # Pydantic models
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â””â”€â”€ transactions.py  # API routes
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ anomaly.py       # z-score & rule-based detection
â”‚       â””â”€â”€ insights.py      # LLM reasoning (OpenAI)
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ load_sample.py       # Generate & ingest test data
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py          # Basic API test
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```
---

## ğŸ§ª Quickstart (Local Setup)

### 1ï¸âƒ£ Clone and setup
```bash
git clone https://github.com/<your-username>/ai-fin-transactions-pipeline.git
cd ai-fin-transactions-pipeline

python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env
```
---

### 2ï¸âƒ£ Run the API
```bash
uvicorn app.main:app --reload
```
ğŸ‘‰ Open http://127.0.0.1:8000/docs to explore the interactive Swagger UI.

ğŸ³ Quickstart (Docker)
```bash
cp .env.example .env
docker compose up --build
```
API available at: http://localhost:8000/docs

Database: localhost:5432 (user: postgres / pass: postgres)

### ğŸ” Core Endpoints
Method	Endpoint	Description
- POST	/ingest	Bulk ingest transactions
- GET	/transactions	List transactions (filter/pagination)
- GET	/anomalies	List high-risk anomalies
- GET	/insights/{transaction_id}	Fetch AI-generated reasoning
- POST	/recompute	Recalculate anomaly scores

### ğŸ§° Environment Variables
| Variable | Description | Default |
|-----------|--------------|----------|
| `APP_ENV` | Environment (dev/prod) | `dev` |
| `DATABASE_URL` | SQLAlchemy DB URI | `postgresql://postgres:postgres@db:5432/transactions` |
| `ANOMALY_Z_THRESHOLD` | Min score to flag anomalies | `3.0` |
| `ANOMALY_AMOUNT_THRESHOLD` | Rule-based high amount | `10000` |
| `OPENAI_API_KEY` | Your OpenAI key | *(empty)* |
| `OPENAI_MODEL` | Model for reasoning | `gpt-4o-mini` |
| `ENABLE_LLM_ANALYSIS` | Enable LLM risk reasoning | `false` |


### ğŸ’¡ AI / LLM Integration
If **ENABLE_LLM_ANALYSIS=true** and **OPENAI_API_KEY** is provided, the service will automatically:
- Analyze flagged anomalies using OpenAIâ€™s Chat Completions API
- Generate short natural-language rationales
- Cache reasoning results in the database

### ğŸ§® Testing
```bash
pytest -v
```

### â˜ï¸ Deployment (Example)
Deploy easily to:
 - Azure Container Apps
 - AWS ECS / Fargate
 - Google Cloud Run
 - Render / Railway / Fly.io

Build and push image:
```bash
docker build -t your-username/ai-fin-transactions-pipeline .
docker push your-username/ai-fin-transactions-pipeline
```
### âœ¨ Author
**Saketh Sai Nigam Kanduri**
- ğŸ“§ kndrsakethms@gmail.com
- ğŸ”— [LinkedIn](www.linkedin.com/in/kandurisakethsainigam)
- ğŸ“ University College Dublin â€” M.Sc. Data & Computational Science
